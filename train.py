import argparse
import os

import torch
import yaml
from tqdm import tqdm

import dataset
import net
import utils

import yaml
from model.baseline.transformerchatgpt import TransformerModel

# âœ… config.yaml í™•ì¸
with open("param.yaml", "r", encoding="utf-8") as f:
    param = yaml.safe_load(f)

train_dir = param["train_dir"]

print(f"ğŸ”¹ train.pyì—ì„œ í™•ì¸ëœ train_dir: {train_dir}")

# âœ… train_dir ë‚´ë¶€ì˜ íŒŒì¼ ëª©ë¡ ì¶œë ¥
import os
if not os.path.exists(train_dir):
    print(f"âŒ {train_dir} ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
else:
    wav_files = [file for file in os.listdir(train_dir) if file.endswith(".wav")]
    print(f"âœ… train.pyì—ì„œ ë°œê²¬ëœ WAV íŒŒì¼ ëª©ë¡: {wav_files[:10]}")  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥

print("CUDA Available:", torch.cuda.is_available())  # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
print("Device Count:", torch.cuda.device_count())   # ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜
print("Current Device:", torch.cuda.current_device())  # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPU ë²ˆí˜¸
print("Device Name:", torch.cuda.get_device_name(0))  # GPU ì´ë¦„ ì¶œë ¥

def get_args() -> argparse.Namespace:
    param_path = "./param.yaml"
    with open("param.yaml", "r", encoding="utf-8") as f:  # UTF-8ë¡œ ì½ê¸°
        param = yaml.safe_load(f)
    parser = argparse.ArgumentParser()

    parser.add_argument("--train-dir", default=param["train_dir"], type=str)
    parser.add_argument("--eval-dir", default=param["eval_dir"], type=str)
    parser.add_argument("--test-dir", default=param["test_dir"], type=str)

    parser.add_argument("--result-dir", default=param["result_dir"], type=str)
    parser.add_argument("--model-dir", default=param["model_dir"], type=str)

    parser.add_argument("--model-path", default=param["model_path"], type=str)

    parser.add_argument("--epochs", default=param["epochs"], type=int)
    parser.add_argument("--batch-size", default=param["batch_size"], type=int)
    parser.add_argument("--lr", default=param["lr"], type=float)

    parser.add_argument("--gpu", default=param["gpu"], type=int)
    parser.add_argument("--n-workers", default=param["n_workers"], type=int)

    parser.add_argument("--sr", default=param["sr"], type=int)
    parser.add_argument("--n-fft", default=param["n_fft"], type=int)
    parser.add_argument("--win-length", default=param["win_length"], type=int)
    parser.add_argument("--hop-length", default=param["hop_length"], type=int)
    parser.add_argument("--n-mels", default=param["n_mels"], type=int)
    parser.add_argument("--power", default=param["power"], type=float)

    args = parser.parse_args()
    return args


def set_seed(seed: int) -> None:
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)






def train(args: argparse.Namespace) -> None:
    print("Training started...")
    os.makedirs(args.result_dir, exist_ok=True)
    os.makedirs(args.model_dir, exist_ok=True)

    # ì˜ˆì‹œ: ë¡œê·¸ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì˜ feature ì°¨ì›ì´ 128ì´ë¼ê³  ê°€ì •
    input_dim = args.n_mels  # ë˜ëŠ” ë°ì´í„°ì— ë§ëŠ” ì°¨ì›
    model = TransformerModel(input_dim=input_dim, d_model=256, nhead=8, num_layers=4).cuda()

    dataloader = dataset.get_train_loader(args)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    criterion = torch.nn.MSELoss()

    for epoch in range(args.epochs):
        print(f"Epoch {epoch+1}/{args.epochs}")
        model.train()

        p_bar = tqdm(dataloader, total=len(dataloader), desc="Training", ncols=100)
        for data in p_bar:
            # ì˜ˆì‹œ: data[0]ì˜ shapeê°€ [batch, 1, 128, 63]ì¸ ê²½ìš°
            log_mel = data[0].squeeze(1)  # ê²°ê³¼: [batch, 128, 63]
            # ê·¸ë¦¬ê³ , time(63)ì´ ì‹œí€€ìŠ¤ ê¸¸ì´, 128ì´ feature dimensionì´ ë˜ì–´ì•¼ í•˜ë¯€ë¡œ, transpose ìˆ˜í–‰
            log_mel = log_mel.transpose(1, 2).cuda()  # ê²°ê³¼: [batch, 63, 128]

            recon_log_mel = model(log_mel)

            # ëª¨ë¸ì˜ receptive field ëŒ€ì‹  ì „ì²´ ì‹œí€€ìŠ¤ì— ëŒ€í•´ ì¬êµ¬ì„± ì˜¤ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            loss = criterion(recon_log_mel, log_mel)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            p_bar.set_description(f"Epoch {epoch + 1}, Loss: {loss.item():.4f}")

    utils.save_model(model, os.path.join(args.model_dir, args.model_path))


if __name__ == "__main__":
    args = get_args()
    os.environ["CUDA_VISIBLE_DEVICES"] = str(args.gpu)
    set_seed(2025)

    train(args)
